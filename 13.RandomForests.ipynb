{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Using Random Forests\n",
    "\n",
    "A **random forest** is a collection of decision trees that each individually make a prediction for an observation. Each tree is formed from a random subset of the training set. The majority decision among the trees is then the predicted value of an observation. Random forests are an example of **ensemble methods**, where the predictions of individual classifiers are used for decision making.\n",
    "\n",
    "The **scikit-learn** class `RandomForestClassifier` can be used for training random forests. For random forests we may consider an additional hyperparameter to tree depth: the number of trees to train. Each tree should individually be shallow, and having more trees should lead to less overfitting.\n",
    "\n",
    "We will still be using the *Titanic* dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import classification_report\n",
    "from random import seed    # Set random seed for reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed(110717)    # Set the seed\n",
    "titanic = pd.read_csv(\"titanic.csv\")\n",
    "titanic_train, titanic_test = train_test_split(titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Growing a Random Forest\n",
    "\n",
    "Let's generate a random forest where I cap the depth for each tree at $m = 5$ and grow 10 trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest1 = RandomForestClassifier(n_estimators=10,    # Number of trees to grow\n",
    "                                 max_depth=5)        # Maximum depth of a tree\n",
    "forest1.fit(X=titanic_train.replace({'Sex': {'male': 0, 'female': 1}}    # Replace strings with numbers\n",
    "                                   ).drop([\"Survived\", \"Name\"], axis=1),\n",
    "            y=titanic_train.Survived)\n",
    "\n",
    "# Example prediction\n",
    "forest1.predict([[2, 0, 26, 0, 0, 30]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.97      0.90       421\n",
      "          1       0.93      0.67      0.78       244\n",
      "\n",
      "avg / total       0.87      0.86      0.85       665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred1 = forest1.predict(titanic_train.replace({'Sex': {'male': 0, 'female': 1}}\n",
    "                                             ).drop([\"Survived\", \"Name\"], axis=1))\n",
    "print(classification_report(titanic_train.Survived, pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest does not perform as well on the training data as a full-grown decision tree, but such a tree overfit. The random forest, in comparison, seems to do as well as a better decision tree so far.\n",
    "\n",
    "## Optimizing Multiple Hyperparameters\n",
    "\n",
    "We now have two hyperparameters to optimize: tree depth and the number of trees to grow. We have a few ways to proceed:\n",
    "\n",
    "1. We could use cross-validation to see which combination of hyperparameters performs the best. Beware that there could be many combinations to check!\n",
    "2. We could use cross-validation to optimize one hyperparameter first, then the next, and so on. While not necessarily producing a globally optimal solution this is less work and likely yields a \"good enough\" result.\n",
    "3. We could randomly pick combinations of hyperparameters and use the results to guess a good combination. This is like 1 but less work.\n",
    "\n",
    "Here I will go with option 2. I will optimize the number of trees to use first, then maximum tree depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>0.848485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>0.848485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.848485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0         1         2         3         4         5  \\\n",
       "10  test_score  0.779412  0.850746  0.805970  0.835821  0.787879  0.848485   \n",
       "20  test_score  0.750000  0.835821  0.805970  0.820896  0.848485  0.863636   \n",
       "30  test_score  0.764706  0.865672  0.805970  0.820896  0.818182  0.863636   \n",
       "40  test_score  0.750000  0.865672  0.820896  0.835821  0.818182  0.863636   \n",
       "60  test_score  0.750000  0.865672  0.820896  0.850746  0.803030  0.863636   \n",
       "80  test_score  0.750000  0.865672  0.805970  0.835821  0.833333  0.878788   \n",
       "100 test_score  0.764706  0.835821  0.820896  0.850746  0.818182  0.878788   \n",
       "\n",
       "                       6         7         8         9  \n",
       "10  test_score  0.833333  0.803030  0.818182  0.787879  \n",
       "20  test_score  0.863636  0.772727  0.803030  0.833333  \n",
       "30  test_score  0.848485  0.833333  0.772727  0.863636  \n",
       "40  test_score  0.833333  0.818182  0.803030  0.848485  \n",
       "60  test_score  0.833333  0.833333  0.787879  0.863636  \n",
       "80  test_score  0.833333  0.803030  0.803030  0.848485  \n",
       "100 test_score  0.848485  0.818182  0.833333  0.848485  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_candidate = [10, 20, 30, 40, 60, 80, 100]    # Candidate forest sizes\n",
    "res1 = dict()\n",
    "\n",
    "for n in n_candidate:\n",
    "    pred3 = RandomForestClassifier(n_estimators=n, max_depth=5)\n",
    "    res1[n] = cross_validate(pred3,\n",
    "                            X=titanic_train.replace({'Sex': {'male': 0, 'female': 1}}    # Replace strings with numbers\n",
    "                                         ).drop([\"Survived\", \"Name\"], axis=1),\n",
    "                            y=titanic_train.Survived,\n",
    "                            cv=10,\n",
    "                            return_train_score=False,\n",
    "                            scoring='accuracy')\n",
    "\n",
    "res1df = DataFrame({(i, j): res1[i][j]\n",
    "                             for i in res1.keys()\n",
    "                             for j in res1[i].keys()}).T\n",
    "\n",
    "res1df.loc[(slice(None), 'test_score'), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10   test_score    0.815074\n",
       "20   test_score    0.819754\n",
       "30   test_score    0.825724\n",
       "40   test_score    0.825724\n",
       "60   test_score    0.827216\n",
       "80   test_score    0.825746\n",
       "100  test_score    0.831762\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1df.loc[(slice(None), 'test_score'), :].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$n = 100$ seems to do well. Now let's pick optimal tree depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_candidate = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]    # Candidate depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>0.761194</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.848485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.878788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.878788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.848485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.880597</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.848485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0         1         2         3         4         5  \\\n",
       "1  test_score  0.720588  0.746269  0.731343  0.716418  0.787879  0.727273   \n",
       "2  test_score  0.750000  0.820896  0.761194  0.835821  0.787879  0.833333   \n",
       "3  test_score  0.735294  0.850746  0.791045  0.850746  0.787879  0.833333   \n",
       "4  test_score  0.764706  0.835821  0.805970  0.850746  0.833333  0.863636   \n",
       "5  test_score  0.735294  0.865672  0.791045  0.835821  0.803030  0.863636   \n",
       "6  test_score  0.764706  0.850746  0.835821  0.850746  0.818182  0.848485   \n",
       "7  test_score  0.750000  0.865672  0.805970  0.835821  0.833333  0.878788   \n",
       "8  test_score  0.764706  0.835821  0.805970  0.850746  0.863636  0.863636   \n",
       "9  test_score  0.779412  0.865672  0.776119  0.880597  0.818182  0.863636   \n",
       "10 test_score  0.750000  0.820896  0.835821  0.835821  0.803030  0.863636   \n",
       "\n",
       "                      6         7         8         9  \n",
       "1  test_score  0.757576  0.696970  0.803030  0.787879  \n",
       "2  test_score  0.803030  0.696970  0.787879  0.772727  \n",
       "3  test_score  0.863636  0.772727  0.818182  0.818182  \n",
       "4  test_score  0.787879  0.833333  0.833333  0.848485  \n",
       "5  test_score  0.833333  0.818182  0.787879  0.833333  \n",
       "6  test_score  0.848485  0.818182  0.848485  0.878788  \n",
       "7  test_score  0.848485  0.818182  0.848485  0.878788  \n",
       "8  test_score  0.848485  0.818182  0.833333  0.848485  \n",
       "9  test_score  0.803030  0.818182  0.848485  0.833333  \n",
       "10 test_score  0.848485  0.787879  0.848485  0.848485  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = dict()\n",
    "\n",
    "for m in m_candidate:\n",
    "    pred3 = RandomForestClassifier(max_depth=m, n_estimators=40)\n",
    "    res2[m] = cross_validate(pred3,\n",
    "                             X=titanic_train.replace({'Sex': {'male': 0, 'female': 1}}    # Replace strings with numbers\n",
    "                                          ).drop([\"Survived\", \"Name\"], axis=1),\n",
    "                             y=titanic_train.Survived,\n",
    "                             cv=10,\n",
    "                             return_train_score=False,\n",
    "                             scoring='accuracy')\n",
    "\n",
    "res2df = DataFrame({(i, j): res2[i][j]\n",
    "                             for i in res2.keys()\n",
    "                             for j in res2[i].keys()}).T\n",
    "\n",
    "res2df.loc[(slice(None), 'test_score'), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1   test_score    0.747522\n",
       "2   test_score    0.784973\n",
       "3   test_score    0.812177\n",
       "4   test_score    0.825724\n",
       "5   test_score    0.816723\n",
       "6   test_score    0.836263\n",
       "7   test_score    0.836352\n",
       "8   test_score    0.833300\n",
       "9   test_score    0.828665\n",
       "10  test_score    0.824254\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2df.loc[(slice(None), 'test_score'), :].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maximum tree depth of $m = 7$ seems to work well. A way to try and combat the path-dependence of this approach would be to repeat the search for optimal forest size but with the new tree depth and so on, but I will not do so here.\n",
    "\n",
    "Let's now see how the new random forest performs on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest2 = RandomForestClassifier(max_depth=9, n_estimators=40)\n",
    "forest2.fit(X=titanic_train.replace({'Sex': {'male': 0, 'female': 1}}    # Replace strings with numbers\n",
    "                                   ).drop([\"Survived\", \"Name\"], axis=1),\n",
    "            y=titanic_train.Survived)\n",
    "\n",
    "survived_test_predict = forest2.predict(X=titanic_test.replace(\n",
    "    {'Sex': {'male': 0, 'female': 1}}\n",
    ").drop([\"Survived\", \"Name\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.93      0.86       124\n",
      "          1       0.88      0.70      0.78        98\n",
      "\n",
      "avg / total       0.84      0.83      0.83       222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(titanic_test.Survived, survived_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest does reasonably well, though it does not appear to be much of an improvement over the decision tree. Given the complexity of the random forest, a simple decision tree would be preferred."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
