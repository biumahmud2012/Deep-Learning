{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Neural Network\n",
    "\n",
    "In this notebook I demonstrate how to train the neural network known as the **multilayer perceptron (MLP)**. We will use a MLP to classify the iris dataset and also a dataset of handwritten digits, in order to detect different characters.\n",
    "\n",
    "Neural networks have a lot of parameters to set when training. These include:\n",
    "\n",
    "* How many hidden layers to have\n",
    "* How many neurons to include in each layer\n",
    "* The activation functions of neurons in the hidden layers\n",
    "* Value of the regularization term to control overfitting (referred to as $\\alpha$)\n",
    "\n",
    "Issues when training a neural network are also accute. These are choices related to the actual optimization algorithm that estimates the parameters used for prediction. For neural networks this fitting process is very involved.\n",
    "\n",
    "MLPs are online algorithms just like perceptrons. This is especially advantageous for training on large datasets that don't necessarily fit into data. Additionally, MLPs are *not* linear classifiers/regressors. This suggests that MLPs are most popular for learning problems that require fitting data that isn't linearly separable.\n",
    "\n",
    "MLPs can be used for classification and regression. This notebook focuses on classification.\n",
    "\n",
    "First, lets load in the datasets we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optical Recognition of Handwritten Digits Data Set\n",
      "===================================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      "References\n",
      "----------\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First, the iris dataset\n",
    "iris_obj = load_iris()\n",
    "iris_data_train, iris_data_test, species_train, species_test = train_test_split(iris_obj.data, iris_obj.target)\n",
    "\n",
    "# Next, the digits dataset\n",
    "digits_obj = load_digits()\n",
    "print(digits_obj.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_obj.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 3, 5, 6])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_data_train, digits_data_test, number_train, number_test = train_test_split(digits_obj.data, digits_obj.target)\n",
    "number_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   6.,  12.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        13.,  13.,   0.,   0.,   0.,   0.,   0.,   7.,  16.,   2.,   0.,\n",
       "         0.,   0.,   0.,   0.,  10.,  12.,   0.,   2.,   0.,   0.,   0.,\n",
       "         0.,  13.,  14.,  16.,  14.,   0.,   0.,   0.,   0.,  11.,  16.,\n",
       "        14.,  13.,   6.,   0.,   0.,   0.,   5.,  13.,   9.,  16.,   5.,\n",
       "         0.,   0.,   0.,   0.,   6.,  15.,  12.,   1.,   0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_data_train[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.,   6.,  12.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,  13.,  13.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   7.,  16.,   2.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,  10.,  12.,   0.,   2.,   0.,   0.],\n",
       "       [  0.,   0.,  13.,  14.,  16.,  14.,   0.,   0.],\n",
       "       [  0.,   0.,  11.,  16.,  14.,  13.,   6.,   0.],\n",
       "       [  0.,   0.,   5.,  13.,   9.,  16.,   5.,   0.],\n",
       "       [  0.,   0.,   0.,   6.,  15.,  12.,   1.,   0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_data_train[0, :].reshape((8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x185050f4eb8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1850339c3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits_data_train[0, :].reshape((8, 8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a MLP to the Iris Data\n",
    "\n",
    "MLP models are implemented via the `MLPClassifier` object in **scikit-learn**. The MLP classifier I train:\n",
    "\n",
    "* Has one hidden layer with 20 neurons\n",
    "* Uses the logistic activation function for the hidden layers\n",
    "* Uses a regularization parameter of $\\alpha = 1$\n",
    "\n",
    "I demonstrate its use below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_iris = MLPClassifier(hidden_layer_sizes=(20,),    # A tuple with the number of neurons for each hidden layer\n",
    "                         activation='logistic',         # Which activation function to use\n",
    "                         alpha=1,                       # Regularization parameter\n",
    "                         max_iter=1000)                 # Maximum number of iterations taken by the solver\n",
    "mlp_iris = mlp_iris.fit(iris_data_train, species_train)\n",
    "mlp_iris.predict(iris_data_train[:1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9821428571428571"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_pred_train = mlp_iris.predict(iris_data_train)\n",
    "accuracy_score(species_pred_train, species_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97368421052631582"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_pred_test = mlp_iris.predict(iris_data_test)\n",
    "accuracy_score(species_pred_test, species_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier has extremely high accuracy for this dataset.\n",
    "\n",
    "## Fitting an MLP to the Digits Dataset\n",
    "\n",
    "Let's now see how the MLP classifier performs for the digits dataset. Again there is only one hidden layer, this one with 50 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_digits = MLPClassifier(hidden_layer_sizes=(50,),\n",
    "                           activation='logistic',\n",
    "                           alpha=1)\n",
    "mlp_digits = mlp_digits.fit(digits_data_train, number_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_digits.predict(digits_data_train[[0], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99777282850779514"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_pred_train = mlp_digits.predict(digits_data_train)\n",
    "accuracy_score(number_pred_train, number_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98222222222222222"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_pred_test = mlp_digits.predict(digits_data_test)\n",
    "accuracy_score(number_pred_test, number_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier shines in these nonlinear contexts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
