{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Data in Python using the $k$-Nearest Neighbors (KNN) Algorithm\n",
    "\n",
    "In this notebook I will demonstrate training and using **$k$-nearest neighbors (KNN)** algorithms with **sklearn**.\n",
    "\n",
    "We will be using the iris dataset, which I load below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_obj = load_iris()\n",
    "\n",
    "flower, species = iris_obj.data, iris_obj.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.6,  3. ,  6.6,  2.1],\n",
       "       [ 5.2,  3.5,  1.5,  0.2],\n",
       "       [ 6.7,  2.5,  5.8,  1.8],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5. ,  3.5,  1.3,  0.3]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flower_train, flower_test, species_train, species_test = train_test_split(flower, species, test_size = 0.1)\n",
    "flower_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Classifier\n",
    "\n",
    "The `KNeighborsClassifier` allows for fitting and predicting using the KNN algorithm. Recall that with KNN, training a model means saving the training data, and predicting is done by picking the most common algorithm the $k$ nearest neighbors of a point.\n",
    "\n",
    "Besides choice of variables, there are two hyperparameters that need to be picked to use KNN: the number of neighbors $k$ used for prediction and the choice of metric for defining distance. Here I will use Euclidean distance, and I start by picking $k = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn1 = KNeighborsClassifier(n_neighbors=1)    # Setting the k parameter\n",
    "knn1.fit(flower_train, species_train)    # Fitting the model\n",
    "knn1.predict(np.array([[7, 3, 5, 2]]))    # A test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 0, 0, 1, 0, 1, 2, 0, 0, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 0, 1, 0, 1, 2, 2, 0, 2, 0, 1, 0, 2, 1, 0, 0, 2, 2, 0,\n",
       "       2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 0, 2, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 2, 1, 1, 1, 0, 2, 2, 0, 2, 2, 0, 0, 1, 2, 2, 0, 0, 0, 1, 1, 1, 2,\n",
       "       2, 0, 0, 1, 0, 0, 0, 2, 1, 0, 1, 1, 1, 2, 0, 2, 1, 0, 2, 0, 0, 1, 2,\n",
       "       0, 1, 2, 0, 1, 1, 1, 0, 1, 1, 2, 2, 0, 1, 0, 0, 2, 2, 2, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1 = knn1.predict(flower_train)\n",
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        46\n",
      "          1       1.00      1.00      1.00        45\n",
      "          2       1.00      1.00      1.00        44\n",
      "\n",
      "avg / total       1.00      1.00      1.00       135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(species_train, pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Of course* the model does perfectly on the training data! (How can it not?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing $k$\n",
    "\n",
    "Let's perform cross-validation to see what $k$ seems to lead to the best predictive accuracy, along with getting a sense of what level of accuracy in prediction we can hope to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_candidate = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "res = dict()\n",
    "\n",
    "for k in k_candidate:\n",
    "    pred2 = KNeighborsClassifier(n_neighbors=k)\n",
    "    res[k] = cross_validate(estimator=pred2,    # The predictor\n",
    "                            X=flower_train,     # Features array\n",
    "                            y=species_train,    # Target array\n",
    "                            cv=10,              # Number of folds (but other meanings exist)\n",
    "                            return_train_score=False,    # Don't return training scores\n",
    "                            scoring='accuracy') # What scores to return (other meanings exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.001012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">4</th>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.001013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">6</th>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">7</th>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">8</th>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">9</th>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">10</th>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0         1         2         3         4         5  \\\n",
       "1  fit_time    0.001001  0.000500  0.000501  0.000514  0.000500  0.000500   \n",
       "   score_time  0.001000  0.000500  0.000500  0.000499  0.000501  0.000501   \n",
       "   test_score  1.000000  1.000000  1.000000  0.933333  0.928571  1.000000   \n",
       "2  fit_time    0.000000  0.000000  0.001001  0.000000  0.001013  0.000000   \n",
       "   score_time  0.001000  0.001000  0.000000  0.001001  0.000000  0.000990   \n",
       "   test_score  1.000000  1.000000  1.000000  0.933333  0.928571  0.923077   \n",
       "3  fit_time    0.000000  0.000000  0.000000  0.001004  0.000998  0.000000   \n",
       "   score_time  0.000991  0.001000  0.001001  0.000997  0.000000  0.000999   \n",
       "   test_score  1.000000  1.000000  1.000000  0.933333  0.928571  1.000000   \n",
       "4  fit_time    0.000000  0.000000  0.001003  0.000000  0.000000  0.000000   \n",
       "   score_time  0.000999  0.001001  0.000000  0.000000  0.000000  0.001006   \n",
       "   test_score  1.000000  1.000000  1.000000  0.933333  0.857143  1.000000   \n",
       "5  fit_time    0.000999  0.000000  0.000000  0.000000  0.000000  0.000995   \n",
       "   score_time  0.000000  0.000000  0.000987  0.001000  0.001022  0.000526   \n",
       "   test_score  0.933333  1.000000  1.000000  0.933333  0.928571  1.000000   \n",
       "6  fit_time    0.000000  0.000000  0.000000  0.001000  0.000000  0.000000   \n",
       "   score_time  0.001001  0.001000  0.000985  0.000000  0.000000  0.000000   \n",
       "   test_score  0.933333  1.000000  1.000000  0.933333  0.928571  1.000000   \n",
       "7  fit_time    0.001000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "   score_time  0.000000  0.001001  0.001000  0.001001  0.001001  0.001000   \n",
       "   test_score  0.933333  1.000000  1.000000  0.933333  0.928571  1.000000   \n",
       "8  fit_time    0.000484  0.000501  0.000000  0.000000  0.000000  0.000000   \n",
       "   score_time  0.000517  0.000000  0.000482  0.000500  0.000501  0.000501   \n",
       "   test_score  0.933333  1.000000  1.000000  0.933333  0.928571  1.000000   \n",
       "9  fit_time    0.000000  0.000484  0.000500  0.000000  0.000000  0.000000   \n",
       "   score_time  0.000500  0.000500  0.000000  0.000501  0.001004  0.001001   \n",
       "   test_score  0.933333  1.000000  1.000000  0.933333  0.928571  1.000000   \n",
       "10 fit_time    0.000000  0.000000  0.000000  0.001000  0.001001  0.001000   \n",
       "   score_time  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "   test_score  0.933333  1.000000  1.000000  0.933333  0.857143  1.000000   \n",
       "\n",
       "                      6         7         8         9  \n",
       "1  fit_time    0.000501  0.000000  0.001001  0.000000  \n",
       "   score_time  0.000499  0.001005  0.000000  0.000000  \n",
       "   test_score  0.833333  1.000000  0.833333  1.000000  \n",
       "2  fit_time    0.001001  0.001001  0.000000  0.000000  \n",
       "   score_time  0.000000  0.000000  0.001003  0.001012  \n",
       "   test_score  0.750000  1.000000  0.833333  0.916667  \n",
       "3  fit_time    0.001001  0.000999  0.001014  0.000000  \n",
       "   score_time  0.001002  0.001001  0.000000  0.000986  \n",
       "   test_score  0.833333  1.000000  0.833333  1.000000  \n",
       "4  fit_time    0.000000  0.000500  0.001009  0.000000  \n",
       "   score_time  0.000646  0.001000  0.001001  0.001013  \n",
       "   test_score  0.750000  1.000000  0.916667  0.916667  \n",
       "5  fit_time    0.000517  0.000000  0.000000  0.000000  \n",
       "   score_time  0.000497  0.000000  0.000997  0.001000  \n",
       "   test_score  0.833333  1.000000  0.916667  1.000000  \n",
       "6  fit_time    0.000000  0.000000  0.000000  0.001000  \n",
       "   score_time  0.001001  0.000999  0.001022  0.000000  \n",
       "   test_score  0.833333  1.000000  0.916667  0.916667  \n",
       "7  fit_time    0.000000  0.000000  0.000000  0.000000  \n",
       "   score_time  0.000000  0.000000  0.000000  0.000520  \n",
       "   test_score  0.833333  1.000000  0.916667  0.916667  \n",
       "8  fit_time    0.000500  0.000500  0.000499  0.000500  \n",
       "   score_time  0.000501  0.000501  0.000501  0.000000  \n",
       "   test_score  0.833333  1.000000  1.000000  0.916667  \n",
       "9  fit_time    0.000000  0.000000  0.000000  0.000000  \n",
       "   score_time  0.001019  0.001000  0.001001  0.001000  \n",
       "   test_score  0.833333  1.000000  1.000000  1.000000  \n",
       "10 fit_time    0.000000  0.000000  0.000000  0.000000  \n",
       "   score_time  0.001001  0.001001  0.001001  0.001000  \n",
       "   test_score  0.833333  1.000000  1.000000  0.916667  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resdf = DataFrame({(i, j): res[i][j]\n",
    "                             for i in res.keys()\n",
    "                             for j in res[i].keys()}).T\n",
    "resdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>test_score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>test_score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>test_score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>test_score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>test_score</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0    1    2         3         4         5         6  \\\n",
       "1  test_score  1.000000  1.0  1.0  0.933333  0.928571  1.000000  0.833333   \n",
       "2  test_score  1.000000  1.0  1.0  0.933333  0.928571  0.923077  0.750000   \n",
       "3  test_score  1.000000  1.0  1.0  0.933333  0.928571  1.000000  0.833333   \n",
       "4  test_score  1.000000  1.0  1.0  0.933333  0.857143  1.000000  0.750000   \n",
       "5  test_score  0.933333  1.0  1.0  0.933333  0.928571  1.000000  0.833333   \n",
       "6  test_score  0.933333  1.0  1.0  0.933333  0.928571  1.000000  0.833333   \n",
       "7  test_score  0.933333  1.0  1.0  0.933333  0.928571  1.000000  0.833333   \n",
       "8  test_score  0.933333  1.0  1.0  0.933333  0.928571  1.000000  0.833333   \n",
       "9  test_score  0.933333  1.0  1.0  0.933333  0.928571  1.000000  0.833333   \n",
       "10 test_score  0.933333  1.0  1.0  0.933333  0.857143  1.000000  0.833333   \n",
       "\n",
       "                 7         8         9  \n",
       "1  test_score  1.0  0.833333  1.000000  \n",
       "2  test_score  1.0  0.833333  0.916667  \n",
       "3  test_score  1.0  0.833333  1.000000  \n",
       "4  test_score  1.0  0.916667  0.916667  \n",
       "5  test_score  1.0  0.916667  1.000000  \n",
       "6  test_score  1.0  0.916667  0.916667  \n",
       "7  test_score  1.0  0.916667  0.916667  \n",
       "8  test_score  1.0  1.000000  0.916667  \n",
       "9  test_score  1.0  1.000000  1.000000  \n",
       "10 test_score  1.0  1.000000  0.916667  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resdf.loc[(slice(None), 'test_score'), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1   test_score    0.952857\n",
       "2   test_score    0.928498\n",
       "3   test_score    0.952857\n",
       "4   test_score    0.937381\n",
       "5   test_score    0.954524\n",
       "6   test_score    0.946190\n",
       "7   test_score    0.946190\n",
       "8   test_score    0.954524\n",
       "9   test_score    0.962857\n",
       "10  test_score    0.947381\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resdf.loc[(slice(None), 'test_score'), :].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the best accuracy is attained when $k = 9$. Let's see how our classifier does on the test set.  It can be slightly different in your Cross validation check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         4\n",
      "          1       1.00      1.00      1.00         5\n",
      "          2       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       1.00      1.00      1.00        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred3 = KNeighborsClassifier(n_neighbors=8)\n",
    "pred3.fit(flower_train, species_train)\n",
    "species_test_predict = pred3.predict(flower_test)\n",
    "print(classification_report(species_test, species_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our KNN classifier does well predicting the setosa species, and the worst behavior is for the virginica species.\n",
    "\n",
    "Considering the graphic below, where species correctly predicted are shown in blue and those incorrectly predicted in red (with shape corresponding to species), we can see this result should be expected; setosa flowers are easily identified while versicolor and virginica would be more difficult to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21644b035c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "marker_map = {0: 'o', 1: 's', 2: '^'}\n",
    "var1, var2 = 0, 1    # Sepal length and sepal width variables\n",
    "for length, width, species in zip(flower_train[:, var1], flower_train[:, var2], species_train[:]):\n",
    "    plt.scatter(x=length, y=width, marker=marker_map[species], c=\"black\")\n",
    "# Plot correct prediction\n",
    "correct = (species_test == species_test_predict)\n",
    "for length, width, species in zip(flower_test[correct, var1], flower_test[correct, var2], species_test[correct]):\n",
    "    plt.scatter(x=length, y=width, marker=marker_map[species], c=\"blue\")\n",
    "for length, width, species in zip(flower_test[np.logical_not(correct), var1],\n",
    "                                  flower_test[np.logical_not(correct), var2],\n",
    "                                  species_test[np.logical_not(correct)]):\n",
    "    plt.scatter(x=length, y=width, marker=marker_map[species], c=\"red\")\n",
    "plt.xlabel(iris_obj.feature_names[var1])\n",
    "plt.ylabel(iris_obj.feature_names[var2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x216452f1e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "marker_map = {0: 'o', 1: 's', 2: '^'}\n",
    "var1, var2 = 2, 3    # Petal length and petal width variables\n",
    "for length, width, species in zip(flower_train[:, var1], flower_train[:, var2], species_train[:]):\n",
    "    plt.scatter(x=length, y=width, marker=marker_map[species], c=\"black\")\n",
    "# Plot correct prediction\n",
    "correct = (species_test == species_test_predict)\n",
    "for length, width, species in zip(flower_test[correct, var1], flower_test[correct, var2], species_test[correct]):\n",
    "    plt.scatter(x=length, y=width, marker=marker_map[species], c=\"blue\")\n",
    "for length, width, species in zip(flower_test[np.logical_not(correct), var1],\n",
    "                                  flower_test[np.logical_not(correct), var2],\n",
    "                                  species_test[np.logical_not(correct)]):\n",
    "    plt.scatter(x=length, y=width, marker=marker_map[species], c=\"red\")\n",
    "plt.xlabel(iris_obj.feature_names[var1])\n",
    "plt.ylabel(iris_obj.feature_names[var2])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
